{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-29 00:38:14,748] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "from pprint import pprint\n",
    "\n",
    "from src.LoraCreator import LORAFactory\n",
    "\n",
    "from peft import PeftModel\n",
    "from IPython.display import display\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "foundation_model_path = \"/home/ec2-user/Llama-2-13B-Chat-fp16\"\n",
    "finetuned_model_path = \"/home/ec2-user/merged_llama2_by_files\"\n",
    "adapter_model_path = \"/home/ec2-user/nghi/llama2_lora_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_factory = LORAFactory(foundation_model_path, finetuned_model_path, adapter_model_path, rank=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load foundational model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573f503862c2436cb12cea81abd17942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load fine-tuned model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40c7505a3ff40e89c34822a14c9eeae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize adapter ...\n"
     ]
    }
   ],
   "source": [
    "lora_factory.load_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing low rank matrix for model.layers.0.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.0.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.1.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.1.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.2.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.2.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.3.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.3.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.4.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.4.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.5.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.5.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.6.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.6.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.7.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.7.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.8.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.8.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.9.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.9.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.10.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.10.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.11.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.11.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.12.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.12.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.13.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.13.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.14.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.14.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.15.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.15.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.16.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.16.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.17.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.17.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.18.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.18.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.19.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.19.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.20.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.20.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.21.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.21.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.22.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.22.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.23.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.23.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.24.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.24.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.25.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.25.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.26.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.26.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.27.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.27.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.28.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.28.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.29.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.29.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.30.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.30.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.31.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.31.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.32.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.32.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.33.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.33.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.34.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.34.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.35.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.35.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.36.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.36.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.37.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.37.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.38.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.38.self_attn.v_proj ...\n",
      "computing low rank matrix for model.layers.39.self_attn.q_proj ...\n",
      "computing low rank matrix for model.layers.39.self_attn.v_proj ...\n"
     ]
    }
   ],
   "source": [
    "lora_factory.create_adapter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load foundational model ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29751ded3c0e472ea4eb02b92c22c431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_lora_model_path = \"/home/ec2-user/nghi/merged_llama2_by_files_LORA\"\n",
    "lora_factory.merge_foundation_adapter_models(merged_lora_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_lora_model = PeftModel.from_pretrained(\n",
    "#         lora_factory.foundation_model,\n",
    "#         lora_factory.adapter_model_path,\n",
    "#         # torch_dtype=torch.float16\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying the LoRA\n"
     ]
    }
   ],
   "source": [
    "# merged_lora_model_path = \"/home/ec2-user/nghi/merged_llama2_by_files_LORA\"\n",
    "# print(\"Applying the LoRA\")\n",
    "# new_merged_model = merged_lora_model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_tokenizer = AutoTokenizer.from_pretrained(lora_factory.foundation_model_path, use_fast=False, legacy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/ec2-user/nghi/merged_llama2_by_files_LORA/tokenizer_config.json',\n",
       " '/home/ec2-user/nghi/merged_llama2_by_files_LORA/special_tokens_map.json',\n",
       " '/home/ec2-user/nghi/merged_llama2_by_files_LORA/tokenizer.model',\n",
       " '/home/ec2-user/nghi/merged_llama2_by_files_LORA/added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_merged_model.save_pretrained(merged_lora_model_path)\n",
    "# base_tokenizer.save_pretrained(merged_lora_model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastchat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
